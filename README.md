NLP practice

1. Folder of news <br>
   kaggle link: https://www.kaggle.com/datasets/kevinmorgado/spanish-news-classification. <br>
   In this Jupyter Notebook I practice the Tokenization, Stemming and Lemmatization tecniques, using the naive bayes model (MultinomialNB). Creating trainings with stemming and lemmatization tecniques so I can      compare both of them with the accuracy results, knowing the lemmatization tecnique have a higher computational cost, but in this case the results were similar, so depends of the porpuse we can select a different tecnique of tokenization. <br>
2. Folder of movies recomendations (recomendacion_peliculas) <br>
    kaggle link: https://www.kaggle.com/datasets/carolzhangdc/imdb-5000-movie-dataset. <br>
   In this Jupyter Notebook I practice the TF-IDF method to visualice the Cosine way to calculate the similarity between vectors (cosine_similarity), using matplotlib library to see the type of graph, in this case    a logaritming graph, I can do this by taking a movie from this dataset and compare it with the rest of the movies and selecting the first ten movies for movies recommendations.


|  Image  | Description |
|---|---|
|  ![image](https://github.com/user-attachments/assets/502a2548-44f4-4976-9e03-a329f36d2dc8) |  This graph has the data out of order, showing the data in csv original order. the dataset has around 5000 columns. |
|  ![image](https://github.com/user-attachments/assets/09b505e3-dc3a-4a7d-868f-8c47f39a483d) | And this graph has a logaritming form due to ordering data from highest to lowest similarity of vectors from this movies   |

3. Folder of similarity <br>
   kaggle link: https://www.kaggle.com/datasets/rtatman/pretrained-word-vectors-for-spanish  <br>

4. Folder Text Clasificator
   
5. Folder Word2Vec:
   There are some texts for training
